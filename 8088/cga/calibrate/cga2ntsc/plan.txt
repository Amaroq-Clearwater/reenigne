Output .dat file for match mode using current combo values

Output:
  RGBI
  Mono composite
  Old CGA
  New CGA
Burst
Background intensity
change character height in graphics modes
character heights >8
Change background/palette combos to show actual RGBI colours instead of just numbers
Keyboard shortcuts
Auto-reload


Add captions for match combos
Make unneeded combo boxes disappear

Write a generic resampling routine
We'd like to do our error calculations in sequential RGB (resampled NTSC) space for speed
  Resample _ntscInput - Lanczos kernel?
  Resample patterns

Attribute clash: Make proper .ntsc files
Attribute clash: Try a monochrome image with no color burst (no resolution reduction)
Attribute clash: Speed up by precomputing perceptual outputs for each pattern/attribute combination
Attribute clash: Diffuse error across entire next block?
Attribute clash: Try all 6 possibilites for overscanColour in AttributeClashImage constructor.
Attribute clash: For monochrome images, try black as well as +BW
Attribute clash: Have multiple windows: RGB output, NTSC output
Attribute clash: Make a BackgroundCalculationImage base class?
Attribute clash: Output image scaling. Scanlines? DirectX?
Attribute clash: Test for repeated iterations

Fix colour metric
  Apply a filter during filterHF?







Requirements for a true-colour file to match:
  One input line corresponds to one output scanline
  Input file is 7 pixels wider than output, so need 647 pixels for full-width
  However, we don't want to resize when switching modes, so add 7 pixels (3 on left, 4 on right) of border colour when comparing


We are getting large areas of flat colour in the output.
How can we do error diffusion within the framework that we have?
  When trying a pattern:
    After each pixel, diffuse the error right and downwards



Error diffusion:
  Sources of error:
    Left from current test (4 hdots)
    Left from last completed block (1 block)
    Up from current test (1 block)
    Up from last completed block (1 line)
  Places where errors are diffused to:
    Right from current test (4 hdots)
    Down from current test (1 block)
    Right on block completion (1 block?)
    Down on block completion (1 line)





Filter input image by (1,4,7,8,7,4,1) and convert to NTSC space
  Need one more NTSC sample than there are pixels in the source image
  Therefore need x+7 before filtering down
Change test blocks to be in NTSC space
Convert weights to NTSC space


(1,1,1,1)*(1,3,3,1) = (1,4,7,8,7,4,1)


phase 0: y+i y+q y-i y-q
phase 1: y+q y-i y-q y+i
phase 2: y-i y-q y+i y+q
phase 3: y-q y+i y+q y-i


On entry to decode, y is 32*ntsc and iq is 16*ntsc



1bpp:
  input: error from above
  input: error from left
  output: error to below
  output: error to right

  Errors can't diffuse to another hdot in the test block, so just have a Bitmap of errors and update it when a block is finalized

In text modes, generalize by having a character-sized block of "test errors"



decode(const Byte* n, int phase):
   n - 0..255
   y - 0..8191
  iq - 0..4095
decode(int y, Complex<int> iq):
   y - 0..8191
  iq - 0..4095
  y2 - 0..255     => _contrast2 is /32
 iq2 - 0..255     => _iqAdjust is /16
 _brightness2 - 0..255

encodeLine:
  mix - 0..8191
  y - 0..8191
  iq - 0..8191
  iq/iqAdjust - 0..131072
  y/32 - 0..255
  (y/32)/_contrast2 - 0..8191


a b c d

(a+b+c+d)/4  (a-c)/2  (b-d)/2  a-b+d-c

a+b+c+d+a-c




        // Filter kernel must be divisible by (1,1,1,1) so that all phases
        // contribute equally.
        int y = n[0] +n[1]*4 +n[2]*7 +n[3]*8 +n[4]*7 +n[5]*4 +n[6];               192 + 4*128 + 64*7 + 8*128 + 192*7 + 128*4 + 64 = 64*8 + 192*8 + 128*16 = 4096
        Complex<int> iq;
        switch (phase) {
            case 0:
                iq.x =  n[0]   -n[2]*7 +n[4]*7 -n[6];                             192 - 64*7 + 192*7 - 64  = 192*8 - 64*8 = 1024
                iq.y =  n[1]*4 -n[3]*8 +n[5]*4;                                   128*4 - 128*8 + 128*4 = 0
                break;
            case 1:
                iq.x = -n[1]*4 +n[3]*8 -n[5]*4;
                iq.y =  n[0]   -n[2]*7 +n[4]*7 -n[6];
                break;
            case 2:
                iq.x = -n[0]   +n[2]*7 -n[4]*7 +n[6];
                iq.y = -n[1]*4 +n[3]*8 -n[5]*4;
                break;
            case 3:
                iq.x = +n[1]*4 -n[3]*8 +n[5]*4;
                iq.y = -n[0]   +n[2]*7 -n[4]*7 +n[6];
                break;
        }
        double y2 = y*_contrast2 + _brightness2;                                  4096/32 = 128
        Complex<double> iq2 = Complex<double>(iq)*_iqAdjust;                      1024/16 = 64
        double r = y2 + 0.9563*iq2.x + 0.6210*iq2.y;                              128 + 61 = 189
        double g = y2 - 0.2721*iq2.x - 0.6474*iq2.y;                              128 - 17 = 111
        double b = y2 - 1.1069*iq2.x + 1.7046*iq2.y;                              128 - 71 = 57
        if (_fixPrimaries)
            return Colour(
                 1.5073*r -0.3725*g -0.0832*b,
                -0.0275*r +0.9350*g +0.0670*b,
                -0.0272*r -0.0401*g +1.1677*b);
        return Colour(r, g, b);

            Vector3<int> mix = Vector3Cast<int>(srgb[0]) +                        32*(189,111,57) = (6048, 3552, 1824)
                4*Vector3Cast<int>(srgb[1]) + 7*Vector3Cast<int>(srgb[2]) +
                8*Vector3Cast<int>(srgb[3]) + 7*Vector3Cast<int>(srgb[4]) +
                4*Vector3Cast<int>(srgb[5]) + Vector3Cast<int>(srgb[6]);
            ++srgb;
            Colour c;
            if (_fixPrimaries) {
                c.x = (0.6689*mix.x + 0.2679*mix.y + 0.0323*mix.z);
                c.y = (0.0185*mix.x + 1.0743*mix.y - 0.0603*mix.z);
                c.z = (0.0162*mix.x + 0.0431*mix.y + 0.8551*mix.z);
            }
            else
                c = Colour(mix.x, mix.y, mix.z);
            Complex<double> iq;
            double y = 0.299*c.x + 0.587*c.y + 0.144*c.z;                         1808 + 2085 + 263 = 4156
            iq.x = 0.596*c.x - 0.275*c.y - 0.321*c.z;                             3605 - 977 - 586 = 2042
            iq.y = 0.212*c.x - 0.528*c.y + 0.311*c.z;                             1282 - 1875 + 567 = -26
            iq /= (_iqAdjust*512);                                                /32 => 63.8, -0.8
            y = (y/32 - _brightness2)/(_contrast2*16);                            (4156/32)/(16/32)
            switch (phase) {
                case 0:
                    *ntsc = byteClamp(y + iq.x);
                    break;
                case 1:
                    *ntsc = byteClamp(y + iq.y);
                    break;
                case 2:
                    *ntsc = byteClamp(y - iq.x);
                    break;
                case 3:
                    *ntsc = byteClamp(y - iq.y);
                    break;
            }
            ++ntsc;
            phase = (phase + 1) & 3;


Convert SRGB image into RGB-subpixels image
Convert NTSC blocks into RGB-subpixels
  Are they evenly distributed?
  Doesn't really matter - we'll work in NTSC-resampled-to-3-dots-per-cycle space, whatever that colour space actually is
  Figure out exact 4-to-3 resampling
    Use it on _inputNTSC
    Use it on patterns


1bpp:
  4 phases each with 3 components
2bpp:
  2 phases each with 3 components
80-column:
  8 hdots, 6 components
40-column:
 16 hdots, 12 components


O(x) = sum(y=-inf..inf, i(y)*sin(pi*x-3*pi*y/4)/(pi*x-3*pi*y/4))/sum(y=-inf..inf, sin(pi*x-3*pi*y/4)/(pi*x-3*pi*y/4))


O(0) = sum(y=-inf..inf, i(y)*sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))/sum(y=-inf..inf, sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))
O(1) = sum(y=-inf..inf, i(y)*sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))/sum(y=-inf..inf, sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))
O(2) = sum(y=-inf..inf, i(y)*sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))


O(0) = sum(y=-inf..-8,0,8, ..inf, i(y)*sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))/sum(y=-inf..inf, sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))
      +sum(y=-inf..-7,1,9, ..inf, i(y)*sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))/sum(y=-inf..inf, sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))
      +sum(y=-inf..-6,2,10,..inf, i(y)*sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))/sum(y=-inf..inf, sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))
      +sum(y=-inf..-5,3,11,..inf, i(y)*sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))/sum(y=-inf..inf, sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))
      +sum(y=-inf..-4,4,12,..inf, i(y)*sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))/sum(y=-inf..inf, sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))
      +sum(y=-inf..-3,5,13,..inf, i(y)*sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))/sum(y=-inf..inf, sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))
      +sum(y=-inf..-2,6,14,..inf, i(y)*sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))/sum(y=-inf..inf, sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))
      +sum(y=-inf..-1,7,15,..inf, i(y)*sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))/sum(y=-inf..inf, sin(pi*0-3*pi*y/4)/(pi*0-3*pi*y/4))

O(1) = sum(y=-inf..-8,0,8, ..inf, i(y)*sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))/sum(y=-inf..inf, sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))
      +sum(y=-inf..-7,1,9, ..inf, i(y)*sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))/sum(y=-inf..inf, sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))
      +sum(y=-inf..-6,2,10,..inf, i(y)*sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))/sum(y=-inf..inf, sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))
      +sum(y=-inf..-5,3,11,..inf, i(y)*sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))/sum(y=-inf..inf, sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))
      +sum(y=-inf..-4,4,12,..inf, i(y)*sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))/sum(y=-inf..inf, sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))
      +sum(y=-inf..-3,5,13,..inf, i(y)*sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))/sum(y=-inf..inf, sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))
      +sum(y=-inf..-2,6,14,..inf, i(y)*sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))/sum(y=-inf..inf, sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))
      +sum(y=-inf..-1,7,15,..inf, i(y)*sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))/sum(y=-inf..inf, sin(pi*1-3*pi*y/4)/(pi*1-3*pi*y/4))

O(2) = sum(y=-inf..-8,0,8, ..inf, i(y)*sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +sum(y=-inf..-7,1,9, ..inf, i(y)*sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +sum(y=-inf..-6,2,10,..inf, i(y)*sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +sum(y=-inf..-5,3,11,..inf, i(y)*sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +sum(y=-inf..-4,4,12,..inf, i(y)*sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +sum(y=-inf..-3,5,13,..inf, i(y)*sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +sum(y=-inf..-2,6,14,..inf, i(y)*sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +sum(y=-inf..-1,7,15,..inf, i(y)*sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))


O(0) = i(0)*sum(y=-inf..-8,0,8, ..inf, sin(    -3*pi*0/4)/(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(1)*sum(y=-inf..-7,1,9, ..inf, sin(    -3*pi*1/4)/(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(2)*sum(y=-inf..-6,2,10,..inf, sin(    -3*pi*2/4)/(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(3)*sum(y=-inf..-5,3,11,..inf, sin(    -3*pi*3/4)/(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(0)*sum(y=-inf..-4,4,12,..inf, sin(    -3*pi*4/4)/(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(1)*sum(y=-inf..-3,5,13,..inf, sin(    -3*pi*5/4)/(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(2)*sum(y=-inf..-2,6,14,..inf, sin(    -3*pi*6/4)/(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(3)*sum(y=-inf..-1,7,15,..inf, sin(    -3*pi*7/4)/(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))

O(1) = i(0)*sum(y=-inf..-8,0,8, ..inf, sin(pi  -3*pi*0/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(1)*sum(y=-inf..-7,1,9, ..inf, sin(pi  -3*pi*1/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(2)*sum(y=-inf..-6,2,10,..inf, sin(pi  -3*pi*2/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(3)*sum(y=-inf..-5,3,11,..inf, sin(pi  -3*pi*3/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(0)*sum(y=-inf..-4,4,12,..inf, sin(pi  -3*pi*4/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(1)*sum(y=-inf..-3,5,13,..inf, sin(pi  -3*pi*5/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(2)*sum(y=-inf..-2,6,14,..inf, sin(pi  -3*pi*6/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(3)*sum(y=-inf..-1,7,15,..inf, sin(pi  -3*pi*7/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))

O(2) = i(0)*sum(y=-inf..-8,0,8, ..inf, sin(pi*2-3*pi*0/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(1)*sum(y=-inf..-7,1,9, ..inf, sin(pi*2-3*pi*1/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(2)*sum(y=-inf..-6,2,10,..inf, sin(pi*2-3*pi*2/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(3)*sum(y=-inf..-5,3,11,..inf, sin(pi*2-3*pi*3/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(0)*sum(y=-inf..-4,4,12,..inf, sin(pi*2-3*pi*4/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(1)*sum(y=-inf..-3,5,13,..inf, sin(pi*2-3*pi*5/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(2)*sum(y=-inf..-2,6,14,..inf, sin(pi*2-3*pi*6/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(3)*sum(y=-inf..-1,7,15,..inf, sin(pi*2-3*pi*7/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))


O(0) = i(0)                                                               /sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(1)*sum(y=-inf..-7,1,9, ..inf, 1/sqrt(2)         /(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(2)*sum(y=-inf..-6,2,10,..inf, -1                /(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(3)*sum(y=-inf..-5,3,11,..inf, 1/sqrt(2)         /(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(0)*sum(y=-inf..-4,4,12,..inf, 0                 /(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(1)*sum(y=-inf..-3,5,13,..inf, -1/sqrt(2)        /(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(2)*sum(y=-inf..-2,6,14,..inf, 1                 /(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))
      +i(3)*sum(y=-inf..-1,7,15,..inf, -1/sqrt(2)        /(    -3*pi*y/4))/sum(y=-inf..inf, sin(    -3*pi*y/4)/(    -3*pi*y/4))

O(1) = i(0)*sum(y=-inf..-8,0,8, ..inf, sin(pi  -3*pi*0/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(1)*sum(y=-inf..-7,1,9, ..inf, sin(pi  -3*pi*1/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(2)*sum(y=-inf..-6,2,10,..inf, sin(pi  -3*pi*2/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(3)*sum(y=-inf..-5,3,11,..inf, sin(pi  -3*pi*3/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(0)*sum(y=-inf..-4,4,12,..inf, sin(pi  -3*pi*4/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(1)*sum(y=-inf..-3,5,13,..inf, sin(pi  -3*pi*5/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(2)*sum(y=-inf..-2,6,14,..inf, sin(pi  -3*pi*6/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))
      +i(3)*sum(y=-inf..-1,7,15,..inf, sin(pi  -3*pi*7/4)/(pi  -3*pi*y/4))/sum(y=-inf..inf, sin(pi  -3*pi*y/4)/(pi  -3*pi*y/4))

O(2) = i(0)*sum(y=-inf..-8,0,8, ..inf, sin(pi*2-3*pi*0/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(1)*sum(y=-inf..-7,1,9, ..inf, sin(pi*2-3*pi*1/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(2)*sum(y=-inf..-6,2,10,..inf, sin(pi*2-3*pi*2/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(3)*sum(y=-inf..-5,3,11,..inf, sin(pi*2-3*pi*3/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(0)*sum(y=-inf..-4,4,12,..inf, sin(pi*2-3*pi*4/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(1)*sum(y=-inf..-3,5,13,..inf, sin(pi*2-3*pi*5/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(2)*sum(y=-inf..-2,6,14,..inf, sin(pi*2-3*pi*6/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))
      +i(3)*sum(y=-inf..-1,7,15,..inf, sin(pi*2-3*pi*7/4)/(pi*2-3*pi*y/4))/sum(y=-inf..inf, sin(pi*2-3*pi*y/4)/(pi*2-3*pi*y/4))


     a       b        c          d                       a-c    b-d
0.750000 0.250000 -0.250000 0.250000   norm = 1.333333      1     0
-0.000000 0.683013 0.500000 -0.183012   norm = 1.333334   -0.5   sqrt(3)/2
-0.000000 -0.183013 0.500000 0.683013   norm = 1.333333   -0.5  -sqrt(3)/2

a-c b-d

v0 = 0.683013
v1 = -0.183012

v0 + v1 = 1/2
v0 - v1 = sqrt(3)/2

v0 = 1/4 + sqrt(3)/4


 a b c d a b c d 0 0 0 0
         ^
a + c - (b + d) == 0

a = b + d - c

(3*a+b-c+d)/4 (3*b+c-d+a)/4 (3*c+d-a+b)/4 (3*d+a-b+c)/4



        int worstHF = 0;
        for (int y = 0; y < _size.y; ++y)
            for (int x = 0; x < (stride << 4); ++x) {
                Vector p(x, y);
                int hf = _error[p] + _error[p+Vector(2, 0)] -
                    (_error[p+Vector(1, 0)] + _error[p+Vector(3, 0)]);
                worstHF = max(worstHF, abs(hf));
            }
        printf("Worst HF = %i\n",worstHF);






//static float sinc(float z)
//{
//    if (z == 0.0f)
//        return 1.0f;
//    z *= M_PI;
//    return sin(z)/z;
//}
//
//static const int lanczosParameter = 1;
//
//int resampleLeftBorder() { return static_cast<int>(lanczosParameter/0.75f); }
//
//int resampleRightBorder()
//{
//    return 1 + static_cast<int>(lanczosParameter/0.75f);
//}
//
//// Lanczos downsampling by a factor of 3/4. n is number of pixels to output.
//void resample(float* input, float* output, int n)
//{
//    static const int a = 1;
//
//    for (int xTarget = 0; xTarget < n; ++xTarget) {
//        float c = 0;
//        float t = 0;
//        int xMin = 1 + static_cast<int>((xTarget - lanczosParameter)/0.75f);
//        int xMax = 1 + static_cast<int>((xTarget + lanczosParameter)/0.75f);
//        for (int x = xMin; x < xMax; ++x) {
//            float p = x*0.75f - xTarget;
//            float s = sinc(p)*sinc(p/lanczosParameter);
//            t += s;
//            c += input[x]*s;
//        }
//        *output = c/t;
//        ++output;
//    }
//}



template<class Sample> class Resampler
{
public:
    Resampler(int a, float scale) : _a(a), _scale(scale) { }

    void downsample(Sample* input, Sample* output, int n)
    {
    }
private:
    int _a;
    float _scale;
};





_mode           0x3d8
   0    40c      0x08
   1    80c      0x09
   2    1bpp     0x1a
   3    2bpp     0x0a

_palette
   0    2/4/6    0x00
   1    3/5/7    0x20
   2   10/12/14  0x10
   3   11/13/15  0x30

Combined mode/palette/background index
   0x00-0x3f  2bpp  0x00000
   0x40-0x4f  1bpp  0x14000
   0x50       40c   0x19000
   0x51       80c   0x19000

Auto modes:
  1bpp        0x40-0x4f
  2bpp        0x00-0x3f
  -HRES       0x00-0x50


  Normal config.h or Berapa?
    At least for cgaart we'd like to be able to switch monitors
      we can do that without full Berapa - in general very few programs need the generality of Berapa.


  input parameters
    contrast
    brightness
    saturation
    hue
    sharpness?
    scaling?




make Bitmap an ALFE object
  Then we can easily make a generic scriptable image-processing tool (superseding image_resample)
  If we do this, it makes sense for the CGA conversion, composite output and rendering to be just more transformations we can perform on the image
    But then what of interactive mode?
      This is equivalent to match+composite+decode+scanlines all in one interactive block. Unless we can break it down and make the UI scriptable
  Need to add a lot of infrastructure
    Vector with x, y members
    size member of bitmap
    rescale function
    constructor from string
  Let's add this later, but for now just do what old cga2ntsc does


What should we do about the "auto" combo members?
    Get rid of auto?
      Ideally we'd generalize it to an arbitrary set of mode/palette combinations
    Should we have seperate auto modes for +HRES and -HRES?
      How does the current config system work?
         0-63 2bpp (_mode == 3)
        64-79 1bpp (_mode == 2)
        80    40c  (_mode == 0)
        81    80c  (_mode == 1)
        Auto goes 0 <= _config < 81 so does not include +HRES
      So, yes
    Auto mode +HRES
    Auto mode -HRES
    Auto palette/background (not in -GRPH)
    Does make any sense to have auto mode but not auto palette?
      Not massively but let's allow it anyway - cga2ntsc is permissive
//   0x08 = 40-column text                        1 palette
//   0x0a = 2bpp graphics                        64 palettes
//   0x18 = 40-column text with 1bpp graphics     1 palette
//   0x1a = 1bpp graphics                        16 palettes

//   0x09 = 80-column text                        1 palette
//   0x0b = high-res 2bpp graphics               64 palettes
//   0x19 = 80-column text with 1bpp graphics     1 palette
//   0x1b = 1bpp graphics, odd bits ignored      16 palettes




    //void setMode(int mode)
    //{
    //    _blink = ((mode & 0x20) != 0);
    //    _bw = ((mode & 4) != 0);
    //    if ((mode & 0x80) != 0) {
    //        _mode = 8 + (mode & 1);
    //        return;
    //    }
    //    mode &= 0x13;
    //    switch (mode) {
    //        case 0: _mode = 0; break;
    //        case 1: _mode = 1; break;
    //        case 2: _mode = 3; break;
    //        case 3: _mode = 7; break;
    //        case 0x10: _mode = 4; break;
    //        case 0x11: _mode = 5; break;
    //        case 0x12: _mode = 2; break;
    //        case 0x13: _mode = 6; break;
    //    }
    //}
    //void setPalette(int palette)
    //{
    //    if (palette == 0xff) {
    //        _palette = 0;
    //        _background = 0x10;
    //    }
    //    else {
    //        _palette = (palette >> 4) & 3;
    //        _background = palette & 0xf;
    //    }
    //}
    //int getMode()
    //{
    //    static int modes[] = {0, 1, 0x12, 2, 0x10, 3, 0x11, 0x13, 0x80, 0x81};
    //    return modes[_mode] | (bw ? 4 : 0) | (blink ? 0x20 : 0);
    //}
    //int getPalette()
    //{
    //    if (_background == 0x10)
    //        return 0xff;
    //    return _background | (_palette << 4);
    //}


Improper modes matching:
  First see if we can improve speed without sacrificing quality by using pixels instead of bytes
  +GRPH +HRES: abcb (each letter represents a byte and a ccycle)
    1: find the best a in the usual way
    2: try all possibilities for b but check entire span of influence of b
    3: find the best c in the usual way
    4: repeat step 2
  In general:
    For each VRAM byte or pixel (in a sensible order):
      For each possibility
        Evaluate possibility over its entire span of influence
      Set byte/pixel to best possibility
    Repeat until nothing changes


Make the config file an interpreted language and make it possible to write loops in it



  Think about how to do interlaced images
    We'd like to be able to see the interlacing happening
      We'd also like to show it non-realistically, avoiding flicker
        Add another option for this
          A fifth element in the interlaceMode combo?
            No need - just adjust vertical size and aspect ratio
              However, users may want to be able to do non-realistic flicker - add this option if requested
    We'd also like to be able to do video with separate input frames for separate output fields
      Can do this by using interlace-video-not-sync, having two config files with different scanlineOffset values, and alternating between them
        Rethink this for CGAArt


  What are are the flicker/interlace possibilities?
    Field 0                          Field 1
    Offset 0  Memory 0  Both         Offset 0  Memory 0  Both         None
    Offset 0  Memory 0  Both         Offset 0  Memory 1  Both         Flicker
    Offset 0  Memory 0  Even         Offset 0  Memory 0  Even         Even
    Offset 0  Memory 0  Odd          Offset 0  Memory 0  Odd          Odd
    Offset 0  Memory 0  Even         Offset 0  Memory 0  Odd          Video
    Offset 0  Memory 0  Even         Offset 0  Memory 1  Even         Even flicker
    Offset 0  Memory 0  Odd          Offset 0  Memory 1  Odd          Odd flicker
    Offset 0  Memory 0  Even         Offset 0  Memory 1  Odd          Video and flicker
    Offset 0  Memory 0  Both         Offset 1  Memory 0  Both         Sync
    Offset 0  Memory 0  Even         Offset 1  Memory 0  Even         Sync even
    Offset 0  Memory 0  Odd          Offset 1  Memory 0  Odd          Sync odd
    Offset 0  Memory 0  Even         Offset 1  Memory 0  Odd          Sync and video
    Offset 0  Memory 0  Odd          Offset 1  Memory 0  Even         Sync and video swapped
    Offset 0  Memory 0  Both         Offset 1  Memory 1  Both         Sync flicker
    Offset 0  Memory 0  Even         Offset 1  Memory 1  Even         Sync even flicker
    Offset 0  Memory 0  Odd          Offset 1  Memory 1  Odd          Sync odd flicker
    Offset 0  Memory 0  Even         Offset 1  Memory 1  Odd          Sync video and flicker
    Offset 0  Memory 0  Odd          Offset 1  Memory 1  Even         Sync video and flicker swapped


Flickering between normal-height and half-height (not very useful)
    Offset 0  Memory 0  Even         Offset 0  Memory 0  Both
    Offset 0  Memory 0  Odd          Offset 0  Memory 0  Both
    Offset 0  Memory 1  Even         Offset 0  Memory 0  Both
    Offset 0  Memory 1  Odd          Offset 0  Memory 0  Both
    Offset 1  Memory 0  Even         Offset 0  Memory 0  Both
    Offset 1  Memory 0  Odd          Offset 0  Memory 0  Both
    Offset 1  Memory 1  Even         Offset 0  Memory 0  Both
    Offset 1  Memory 1  Odd          Offset 0  Memory 0  Both
    Offset 0  Memory 0  Both         Offset 0  Memory 0  Even
    Offset 0  Memory 1  Both         Offset 0  Memory 0  Even
    Offset 1  Memory 0  Both         Offset 0  Memory 0  Even
    Offset 1  Memory 1  Both         Offset 0  Memory 0  Even
    Offset 0  Memory 0  Both         Offset 0  Memory 0  Odd
    Offset 0  Memory 1  Both         Offset 0  Memory 0  Odd
    Offset 1  Memory 0  Both         Offset 0  Memory 0  Odd
    Offset 1  Memory 1  Both         Offset 0  Memory 0  Odd
    Offset 0  Memory 0  Even         Offset 0  Memory 1  Both
    Offset 0  Memory 0  Odd          Offset 0  Memory 1  Both
    Offset 0  Memory 1  Even         Offset 0  Memory 1  Both
    Offset 0  Memory 1  Odd          Offset 0  Memory 1  Both
    Offset 1  Memory 0  Even         Offset 0  Memory 1  Both
    Offset 1  Memory 0  Odd          Offset 0  Memory 1  Both
    Offset 1  Memory 1  Even         Offset 0  Memory 1  Both
    Offset 1  Memory 1  Odd          Offset 0  Memory 1  Both
    Offset 0  Memory 0  Both         Offset 0  Memory 1  Even
    Offset 0  Memory 1  Both         Offset 0  Memory 1  Even
    Offset 1  Memory 0  Both         Offset 0  Memory 1  Even
    Offset 1  Memory 1  Both         Offset 0  Memory 1  Even
    Offset 0  Memory 0  Both         Offset 0  Memory 1  Odd
    Offset 0  Memory 1  Both         Offset 0  Memory 1  Odd
    Offset 1  Memory 0  Both         Offset 0  Memory 1  Odd
    Offset 1  Memory 1  Both         Offset 0  Memory 1  Odd
    Offset 0  Memory 0  Even         Offset 1  Memory 0  Both
    Offset 0  Memory 0  Odd          Offset 1  Memory 0  Both
    Offset 0  Memory 1  Even         Offset 1  Memory 0  Both
    Offset 0  Memory 1  Odd          Offset 1  Memory 0  Both
    Offset 1  Memory 0  Even         Offset 1  Memory 0  Both
    Offset 1  Memory 0  Odd          Offset 1  Memory 0  Both
    Offset 1  Memory 1  Even         Offset 1  Memory 0  Both
    Offset 1  Memory 1  Odd          Offset 1  Memory 0  Both
    Offset 0  Memory 0  Both         Offset 1  Memory 0  Even
    Offset 0  Memory 1  Both         Offset 1  Memory 0  Even
    Offset 1  Memory 0  Both         Offset 1  Memory 0  Even
    Offset 1  Memory 1  Both         Offset 1  Memory 0  Even
    Offset 0  Memory 0  Both         Offset 1  Memory 0  Odd
    Offset 0  Memory 1  Both         Offset 1  Memory 0  Odd
    Offset 1  Memory 0  Both         Offset 1  Memory 0  Odd
    Offset 1  Memory 1  Both         Offset 1  Memory 0  Odd
    Offset 0  Memory 0  Even         Offset 1  Memory 1  Both
    Offset 0  Memory 0  Odd          Offset 1  Memory 1  Both
    Offset 0  Memory 1  Even         Offset 1  Memory 1  Both
    Offset 0  Memory 1  Odd          Offset 1  Memory 1  Both
    Offset 1  Memory 0  Even         Offset 1  Memory 1  Both
    Offset 1  Memory 0  Odd          Offset 1  Memory 1  Both
    Offset 1  Memory 1  Even         Offset 1  Memory 1  Both
    Offset 1  Memory 1  Odd          Offset 1  Memory 1  Both
    Offset 0  Memory 0  Both         Offset 1  Memory 1  Even
    Offset 0  Memory 1  Both         Offset 1  Memory 1  Even
    Offset 1  Memory 0  Both         Offset 1  Memory 1  Even
    Offset 1  Memory 1  Both         Offset 1  Memory 1  Even
    Offset 0  Memory 0  Both         Offset 1  Memory 1  Odd
    Offset 0  Memory 1  Both         Offset 1  Memory 1  Odd
    Offset 1  Memory 0  Both         Offset 1  Memory 1  Odd
    Offset 1  Memory 1  Both         Offset 1  Memory 1  Odd

Offset 1 on both fields is equivalent to offset 0 on both fields
    Offset 1  Memory 0  Both         Offset 1  Memory 0  Both
    Offset 1  Memory 1  Both         Offset 1  Memory 0  Both
    Offset 1  Memory 0  Even         Offset 1  Memory 0  Even
    Offset 1  Memory 0  Odd          Offset 1  Memory 0  Even
    Offset 1  Memory 1  Even         Offset 1  Memory 0  Even
    Offset 1  Memory 1  Odd          Offset 1  Memory 0  Even
    Offset 1  Memory 0  Even         Offset 1  Memory 0  Odd
    Offset 1  Memory 0  Odd          Offset 1  Memory 0  Odd
    Offset 1  Memory 1  Even         Offset 1  Memory 0  Odd
    Offset 1  Memory 1  Odd          Offset 1  Memory 0  Odd
    Offset 1  Memory 0  Both         Offset 1  Memory 1  Both
    Offset 1  Memory 1  Both         Offset 1  Memory 1  Both
    Offset 1  Memory 0  Even         Offset 1  Memory 1  Even
    Offset 1  Memory 0  Odd          Offset 1  Memory 1  Even
    Offset 1  Memory 1  Even         Offset 1  Memory 1  Even
    Offset 1  Memory 1  Odd          Offset 1  Memory 1  Even
    Offset 1  Memory 0  Even         Offset 1  Memory 1  Odd
    Offset 1  Memory 0  Odd          Offset 1  Memory 1  Odd
    Offset 1  Memory 1  Even         Offset 1  Memory 1  Odd
    Offset 1  Memory 1  Odd          Offset 1  Memory 1  Odd

Non-preferred field order (memory 1 on field 0)
    Offset 0  Memory 1  Both         Offset 0  Memory 0  Both
    Offset 1  Memory 1  Both         Offset 0  Memory 0  Both
    Offset 0  Memory 1  Both         Offset 0  Memory 1  Both
    Offset 1  Memory 1  Both         Offset 0  Memory 1  Both
    Offset 0  Memory 1  Both         Offset 1  Memory 0  Both
    Offset 0  Memory 1  Both         Offset 1  Memory 1  Both
    Offset 0  Memory 1  Even         Offset 0  Memory 0  Even
    Offset 1  Memory 1  Even         Offset 0  Memory 0  Even
    Offset 0  Memory 1  Even         Offset 0  Memory 1  Even
    Offset 1  Memory 1  Even         Offset 0  Memory 1  Even
    Offset 0  Memory 1  Even         Offset 1  Memory 0  Even
    Offset 0  Memory 1  Even         Offset 1  Memory 1  Even
    Offset 0  Memory 1  Odd          Offset 0  Memory 0  Odd
    Offset 1  Memory 1  Odd          Offset 0  Memory 0  Odd
    Offset 0  Memory 1  Odd          Offset 0  Memory 1  Odd
    Offset 1  Memory 1  Odd          Offset 0  Memory 1  Odd
    Offset 0  Memory 1  Odd          Offset 1  Memory 0  Odd
    Offset 0  Memory 1  Odd          Offset 1  Memory 1  Odd
    Offset 0  Memory 1  Odd          Offset 0  Memory 0  Even
    Offset 1  Memory 1  Odd          Offset 0  Memory 0  Even
    Offset 0  Memory 1  Even         Offset 0  Memory 0  Odd
    Offset 1  Memory 1  Even         Offset 0  Memory 0  Odd
    Offset 0  Memory 1  Odd          Offset 0  Memory 1  Even
    Offset 1  Memory 1  Odd          Offset 0  Memory 1  Even
    Offset 0  Memory 1  Even         Offset 0  Memory 1  Odd
    Offset 1  Memory 1  Even         Offset 0  Memory 1  Odd
    Offset 0  Memory 1  Odd          Offset 1  Memory 0  Even
    Offset 0  Memory 1  Even         Offset 1  Memory 0  Odd
    Offset 0  Memory 1  Odd          Offset 1  Memory 1  Even
    Offset 0  Memory 1  Even         Offset 1  Memory 1  Odd

Non-preferred field order (offset 1 on field 0):
    Offset 1  Memory 0  Both         Offset 0  Memory 0  Both
    Offset 1  Memory 0  Even         Offset 0  Memory 0  Even
    Offset 1  Memory 0  Odd          Offset 0  Memory 0  Odd
    Offset 1  Memory 0  Even         Offset 0  Memory 0  Odd
    Offset 1  Memory 0  Odd          Offset 0  Memory 0  Even

Non-preferred field order (odd scanlines on field 0):
    Offset 0  Memory 0  Odd          Offset 0  Memory 0  Even

Non-preferred memory layout (odd scanlines in bank 0):
    Offset 0  Memory 0  Odd          Offset 0  Memory 1  Even

Non-preferred memory layout (offset 1 in bank 0):
    Offset 1  Memory 0  Both         Offset 0  Memory 1  Both
    Offset 1  Memory 0  Even         Offset 0  Memory 1  Even
    Offset 1  Memory 0  Odd          Offset 0  Memory 1  Odd
    Offset 1  Memory 0  Even         Offset 0  Memory 1  Odd
    Offset 1  Memory 0  Odd          Offset 0  Memory 1  Even



Decide where to put CGAComposite
  CGAEncoder will need one
  Should OutputWindow have its own one?
    Probably a good idea if it's running on a separate thread - less information sharing
    Does it need one?
      In what format should CGAMatcher send data to OutputWindow?
        Currently it sends it in RGBI format
          Let's stick with this for now
        Ideally we'd have some intermediate format that's useful for cgaart
          Using the format from cga_art.txt (or anything earlier than NTSC) means that OutputWindow will need a CGAComposite
    Is there a reason why OutputWindow would be using old CGA and CGAMatcher would be using new CGA?
      old/new CGA control should be logically placed with other output controls like brightness, all of which are instanced (one for matching, one for displaying)
        We can display without matching (show mode) or match without displaying (command line mode with data-only output)


Think about how to do matching with graphics modes with more than 2 scanlines per row
  Option 1: Re-test and iterate as with improper modes
  Option 2: Treat both rows as a single block and iterate through all combinations      <-- do this for now
    Can we use this for improper modes as well? At least for +HRES+GRPH?
      Would need to test 2^24 possibilities for abcb
        Even if this is temporally feasable using the gamut method, the memory costs may be impractical


Think about how to do temporal diffusion
  Load error file
  Save error file
  What about interlaced images?
    Sync modes
      Diffuse errors by 33ms
      Independent fields
        Match even scanlines on even field, odd scanlines on odd field
      Dependent fields
        Match as if high-res
    Non-sync modes
      Diffuse errors by 17ms
      Two datasets
        Do two matches
      One dataset
        Do one match



    Should we not have a rendering thread, since we'd like to be able to render a field in 16ms anyway for emulators?
      Let's try to start out without a rendering thread, and add one if we need it for UI responsiveness
        Berapa might have a rendering thread anyway to improve performance
        We'll want a rendering thread for FFTW
    When the matcher finishes something, it needs to send a message to the UI thread to request a redraw of a particular scanline (or set of scanlines)
      Have a (locked) set of bits representing the scanlines which need to be redrawn
      When the update message is received, the UI thread re-renders all modified scanlines
      How can we consolidate duplicate messages?
        Instead of using the message queue, signal an event?
          MsgWaitForMultipleObjects
            Figure out how we want to do idle processing
              Always use MsgWait instead of GetMessage?
              Have another overrideable function
      RGBI->composite is very fast compared to composite->output (which needs to redraw the entire frame each time) so let's initially not bother with the bitset



      CGAOutput just reads/writes bitmaps
      CGAOutput <-> Program <-> CGA2NTSCWindow <-> OutputWindow
        Actually CGA2NTSCWindow can have a pointer to CGAOutput to simplify UI interactions
      We want to display a subBitmap of the output bitmap
        So, make draw() copy the relevant part of the output bitmap to the paint bitmap
          Why do we need this complicated setNextBitmap() business?
            It was done for capture_live which decodes on a separate thread
            We don't actually need to call setNextBitmap() more than once if we don't care about tearing
            As long as we do the final write (i.e. copy from output) in the same thread as the paint we won't tear anyway


e has type LValue<Bitmap> and value (ConfigFile*, "inputPicture")
  e.value<LValue> is (ConfigFile*, "inputPicture")
  e.value<LValue>.rValue() is BitmapValue (as returned by converting from string)
    However, we need it to be Structure* in order to be able to use . on it
      It ought to be possible to use . on an rValue
        Anything that we can use . on has to be a Structure* (in ALFE everything will be a Structure* but for ConfigFiles we allow other types for convenience)
        Perhaps rvalue . is a similar convenience feature
          How do we determine if we should use rvalue or not?
            inputPicture is an lvalue because we can assign to it, so it represented by an LValue type
          Who should own the Structure*?
            Ideally the ConfigFile (or other parent) could continue to own it, and we'd automatically get the Structure* from that
              To that we need some way to go from an Value<arbitrary thing deriving from Structure> to a Structure*
                Perhaps we can add a method to Any which is like value<> but instead pointer<>
                  Trouble with that is that the Any::Body classes are unrelated and reinterpret_cast<> could break
                  Also we'd like to able to continue to use the existing Structure* stuff, we don't want to force Structures to be owned by ConfigFiles
                  Really Structure must either always be owned by ConfigFile or never owned by ConfigFile, and we've already chosen never
                    So how can we keep track of our Bitmaps?
                      For the purpose of cga2ntsc we can have a single one, but it would be nice to be a little more general
                        Perhaps it would be better to have ConfigFile own all the Structures
                        Why did we do it this way in the first place?
                          Because for Berapa we didn't want the ConfigFile to have an active role after construction
                            So we've got an ownership problem in general - either objects are owned by ConfigFile (in which case we can't have the Berapa separation) or they aren't (and we can't have the Bitmap ownership)
                              What if we use Reference<Structure> instead of Structure*?
        Ultimately this problem needs to be solved by ALFE
        Solution: a set of owning objects are used in ConfigFile but for the purposes of ALFE/Berapa they can instantiate other objects
          This will require some rework in Berapa
          For Berapa, we don't really want to have make Component a Handle/Body system
            So: change Reference<Component> and Structure* to Reference<Structure>
            When we create a Structure, put it in the Value as Reference<Structure>
              Let's continue to use Structure* for non-owning places like LValue (convert with &*ref)
            This doesn't work because we want to have components that are sub-components of other components
        Let's solve this by just having a single Bitmap for now, and if at some point we want more we can do a Berapa-like solution or have some mechanism for deallocating Structure* on assignment




    Do any display settings other than brightness/contrast/hue/saturation/cga-output affect matching?
      Matching occurs at the step before size and scanlines are applied
      Filtering doesn't affect colour space, so should not affect matching
        This is not quite true - best fit for HF data depends on luma bandwidth
          So, add a sharpness control to the match decoding controls
          Is there an equivalent for comb filtering?
            Yes! So we need to have the comb filter controls on the matcher as well as the output
    After matching, we should be able to change mode/palette as well
    In general, these problems will be solved by having cga2ntsc be the "import module" for cgaart
      What should the two windows show?
        cgaart window shows final output
        import window shows input before matching?
        Model as a sequence of transformations:
                                             cga2ntsc   ?                           cgaart
                                                v       v                             v
          Input image -> colour space adjusted -> match -> colour space adjusted -> output
      If we display post-match (i.e. CGA output) we'd really need to have all the controls that cga2ntsc has
      When moving from cga2ntsc to cgaart, let's add import as a whole separate function, keeping the current cga2ntsc as the basis of cgaart
        The import module will be able to change brightness/contrast/saturation/hue of the import image
        cga2ntsc doesn't need to have any facilities for changing the brightness/contrast/saturation/hue of input images, so only need one set of these settings
          For batch usage, cga2ntsc is not really the proper tool for this (using >8 bits per channel might improve results for extreme settings changes, but this is a corner case)
        We will need to compute/use a sharpness setting and apply comb filters for matching
        We can get rid of the distinction between show mode and match mode - show mode is just matching in RGBI mode and outputting in composite
        Actually cgaart+import is essentially two cga2ntsc windows that share the same data, but have different settings in general
        Old-cga2ntsc "Show mode" is essentially matching with RGBI output then switching to composite. So make it require two steps
          To do it in batch mode will require two instantiations


    Display - right of image
      Colour
        add2(&_newCGA);
        _brightness.setHost(this);
        _saturation.setHost(this);
        _contrast.setHost(this);
        _hue.setHost(this);
      Filter
        _chromaBandwidth.setHost(this);
        _lumaBandwidth.setHost(this);
        add2(&_combFilterVertical);
        add2(&_combFilterTemporal);
      Scanlines
        add2(&_scanlineProfile);
        _scanlineWidth.setHost(this);
        add2(&_scanlineBleeding);
      Size
        _zoom.setHost(this);
        _aspectRatio.setHost(this);
    Matching - below image
        add2(&_matchMode);
      CGA mode
        add2(&_mode);             add2(&_bwCheckBox);        add2(&_blinkCheckBox);
        add2(&_palette);        add2(&_background);
        add2(&_scanlinesPerRow);        add2(&_scanlinesRepeat);
        add2(&_phaseCheckBox);          add2(&_interlaceCombo);
      Other
        _diffusionHorizontal.setHost(this);
        _diffusionVertical.setHost(this);
        _diffusionTemporal.setHost(this);
        _quality.setHost(this);
        add2(&_characterSetCombo);



Resources about UI layout and dialog units:
https://msdn.microsoft.com/en-us/library/dn742486.aspx
https://msdn.microsoft.com/en-us/library/ms645502.aspx
https://msdn.microsoft.com/en-us/library/dd145132.aspx



FIR filters and SIMD:
  Composite data
                          Comb filtering (or just duplicate)
                          Demodulate chroma
                          Filter chroma and luma
  14MHz sRGB
                          Linearize
  14MHz linear
                          Horizontal and vertical filtering
  linear output
                          Bleed
  clipped linear output
                          Delinearize
  sRGB output

Figure out set of functions we want to build for desired features and performance
  Decoding filter
    16 bits
    1 bit for overflow
    do comb filter separately
    Pre-broadcast filter kernels
    Saturate. Results 0 and 255 indicate clipping
    No resampling
  Horizontal filter
    Resampling

  Vertical filter
    Work on entire scanlines at once in order to help cache


534 sections per frame
  For each section we'll need 6 FFTs ((forward, backward)*(Y, I, Q))
Each FFT takes 1.8364 microseconds. 6*534*1.8364 is 5883.8256 us per frame or 170Hz.
_chromaTime forward transforms can be half-length, so 0.95508, giving 4942.57584 us per frame or 202Hz


4 compute pattern for graphics mode
8 compute pattern for hres text mode
16 compute pattern for lres text mode
64 minimal for a trial (chroma)
128 minimal for a trial (luma)
256 standard block (chroma)
512 standard block (luma)


Scanline profiles:
  Circle
    Fix circular scanlines at small widths: To avoid aliasing we should sample at high frequency (scale up by N) and then take every Nth sample after the FFT
    May not be practical to compute directly
    Use FFTs for this
      If we have the FT of the desired scanline pattern, we can sample it with N multiplies and adds
  Gaussian
    This will also need the band-limiting treatment to get the correct result for small widths
      integral(exp(a*x*x)*cos(2*pi*f*x)*dx) = (sqrt(pi)*exp(pi*pi*f*f/a)*(erfi((a*x+i*pi*f)/sqrt(a))-erfi((-a*x+i*pi*f)/sqrt(a)))/(4*sqrt(a)) + c
      integral(exp(-a*x*x)*cos(2*pi*x*f)*dx) = (i*sqrt(pi)*exp(-pi*pi*f*f/a)*(erfi((pi*f-i*a*x)/sqrt(a))-erfi((pi*f+i*a*x)/sqrt(a)))/(4*sqrt(a)) + c
      integral(exp(-a*x*x)*exp(2*pi*i*x*f)*dx) = -(i*sqrt(pi)*exp(-pi*pi*f*f/a)*erfi((pi*f+i*a*x)/sqrt(a))/(2*sqrt(a)) + c
      erfi(x) = -i*erf(i*x)
      erf can be computed via Maclauren series (7.1.5) or 7.1.6 in http://people.math.sfu.ca/~cbm/aands/page_297.htm
  Parabolic
  Sine


  Does it actually make sense for the PLL width/height to change over time? How would that actually work?
    The only reason these are not fixed at 910/262.5 is that we'd like to be able to use extended canvases. This reason does not extend to variable PLLs
    Since we need variable scanline lengths for PLL, it's only a small step to allow the PLL to change too, but there are complications:
      We can't then divide up into scanlines/frames as a post-processing step (since we don't know what the PLL width is at each point)
      The actual effect of changing PLL width is underspecified (what happens to the PLL phase?)
      So, let's move PLL width/height into the non-temporal part of CGAData

    Can we do sub-hdot positioning?
      Not in horizontal scaling - we use the same kernel for each scanline
      Doing it in decode might be possible but fiddly
      I don't think we really need sub-hdot positioning anyway (sync position granulatity is at least 4 hdots)



Extended mode bits:
  0     1 +HRES
  1     2 +GRPH
  2     4 +BW
  3     8 +VIDEO ENABLE
  4  0x10 +1BPP
  5  0x20 +ENABLE BLINK
  6  0x40 Phase 1
  7  0x80 auto mode
  8 0x100 >2 scanlines per row
  9 0x200 odd column

-GRPH      - patterns always coincide with characters, don't care about column bits
+GRPH-HRES - patterns are always 1 nybble wide. We only use the column bit to decide which nybble to adjust in rowData, but always render 4 hdots
+GRPH+HRES - patterns are always 1 byte wide. We use the column bit to decide whether to adjust low or high byte in dataBits
